{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Naive Bayes Overview</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- Explain each element of the Bayes Theorem \n",
    "- Apply Bayes Theorem to classification\n",
    "- Explain when and when __not__ to apply Naive Bayes\n",
    "- Walk through a example of Naive Bayes text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is classification?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Predict a single category from a collection of discrete categories.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>Dog or Lion?</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/prediction.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Methods for Classification</h2></center>\n",
    "\n",
    "1. Hand-written Rules\n",
    "1. Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Hand-written Rules</h2></center>\n",
    "\n",
    "\n",
    "Write a series of `if then` statements by hand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples:\n",
    "\n",
    "- If \"Viagra\" or \"Nigerian Prince\" appear in an email, then email is spam.\n",
    "- If words such as \"worst ever\" and \"terrible\" appear in a movie review, then the review is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are the downsides of rules?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) Time intensive - To be complete, a large set of rules would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2) Brittle - Rules could not easily apply to new situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Machine Learning</h2></center>\n",
    "<br>\n",
    "<br>\n",
    "<center>Learn patterns from the data</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Machine Learning for Classification</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/pipeline.jpg\" width=\"70%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>Bayes Rule</h2></center>\n",
    "<center><img src=\"images/Thomas_Bayes.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*l0MccMHzSjtpJ_mGaItVfA.jpeg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do we want to use Bayes Rule as our ML algorithm?\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://static1.squarespace.com/static/591e58f72994cab66b93f891/t/591f89a39c03e001d1e3b17e/1495241602853/bayes-rule-e1350930203949.png\" width=\"85%\"/></center>\n",
    "\n",
    "Allows us to evaluate our hypothesis, given our prior beliefs and new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes Theorem for Classification\n",
    "-----\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Likelihood\n",
    "------\n",
    "\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"70%\"/></center>\n",
    "\n",
    "How likely we are to observe the data point given a specific label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Class Prior\n",
    "------\n",
    "\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"70%\"/></center>\n",
    "\n",
    "How likely we are to observe each of the label, ignoring the data.\n",
    "\n",
    "Also called base-rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Predictor Prior Probability\n",
    "------\n",
    "\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"70%\"/></center>\n",
    "\n",
    "How likely we are to observe any given data point $p(doc)$ \n",
    "\n",
    "In the case of text classification, probability of observing an individual document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Posterior Probability\n",
    "------\n",
    "\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"70%\"/></center>\n",
    "\n",
    "Predict probability of a label given a new observation.\n",
    "\n",
    "The goal of machine learning classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Naive Bayes for Text Classification</h2></center>\n",
    "\n",
    " $$p(\\text{class }| \\text{ doc}) = \\frac{p(\\text{doc } | \\text{ class}) \\times p(\\text{class})}{p(\\text{doc})}$$\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $p(\\text{class }| \\text{ doc})$: observing a particular class given a document (Posterior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $p(\\text{doc } | \\text{ class})$: observing a document given a particular class (Likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $p(\\text{class})$: observing each of the classes (Prior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $p(\\text{doc})$: observing an individual document (Marginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dropping p(doc) from the equation\n",
    "-----\n",
    "\n",
    "Since all calculated probabilities have $p(\\text{doc})$ as their denominator, we can eliminate the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Predicting the class for a new document</h2></center>\n",
    "\n",
    "$$P(\\text{class } |\\text{ doc}) = P(\\text{class}) \\times (P(word_1 \\text{ | class}) \\cdot P(word_2 \\text{ | class}) \\cdot ... \\cdot P(word_n \\text{ | class}))$#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ P(\\text{class } |\\text{ doc}) = P(\\text{class }) ‚Ä¢  \\prod_{i=1}^n P(word_i | \\text{class })$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://medium.com/@theflyingmantis/text-classification-in-nlp-naive-bayes-a606bf419f8c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Being Naive: Bayes' Greatest Strength & Greatest Weakness</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/dare_to_be_naive.jpeg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Naive: Each word conditionally independent for each label\n",
    "</h2></center>\n",
    "\n",
    "\n",
    "<center>What about combinations of words? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Naive Bayes works very well in practice</h2></center>\n",
    "\n",
    "<center><img src=\"http://www.azquotes.com/picture-quotes/quote-well-it-may-be-all-right-in-practice-but-it-will-never-work-in-theory-warren-buffett-86-75-88.jpg\" width=\"75%\"/></center>\n",
    "\n",
    "__Despite feature independence assumption__, Naive Bayes is very common and useful in real world applications: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Message filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is a review positive üëç or negative üëé?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Medical diagnosis (‚ûï or ‚ûñ)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>In text classification features are critical</h2></center>\n",
    "\n",
    "<center><img src=\"images/supervised_learning.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What features might you want to use for text classification? </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Data:\n",
    "    - Individual words\n",
    "    - Phrases\n",
    "    - Punctuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Metadata:\n",
    "    - Length of document\n",
    "    - Language\n",
    "    - Sender or receiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Naive Bayes \"embarrassingly parallelizable\"</h2></center>\n",
    "\n",
    "Each feature weight can be learned separately for each class.\n",
    "\n",
    "Thus it can be learned at the same time on a separate computer / core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://alitarhini.wordpress.com/2011/03/02/parallel-naive-bayesian-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Bayes Rule is one of the most important theorems in Statistics.\n",
    "- You should be apply to write Bayes Rule from memory and able to Bayes Rule to novel situations.\n",
    "- Naive Bayes (NB) is among the simplest (and most effective) machine learning classifiers.\n",
    " \n",
    "- Discrete NB works well for text classification.\n",
    "- However, NB does not work when features correlation are needed to separate classes.\n",
    "- Gaussian Naive Bayes is a logical extension for continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Further Study\n",
    "------\n",
    "\n",
    "- [Guassian Naive Bayes formula](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes)\n",
    "- Modeling a combination of discrete and real-valued features\n",
    "- Non-guassian Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
