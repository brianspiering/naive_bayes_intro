{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Implement Naive Bayes <br>From Scratch</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Bayes' Theorem</h2></center>\n",
    "\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/bayes_rule.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Training Naive Bayes</h2></center>\n",
    "\n",
    "1. Acquire labeled data\n",
    "1. Preprocess data\n",
    "1. Calculate document class priors\n",
    "1. Calculate word by class conditional probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Acquire data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "corpus  = [\"🐈 🐯 🐱 🐩 🐱\", \n",
    "           \"🐶 🐶 🐈 🐶 🐩 🐈 🐶 🐶\", \n",
    "           \"🐈 🐈 🐯 🐶 🐈\",  \n",
    "           \"🐈 🐈 🐈\",\n",
    "           \"🐶 🐶 🐯 🐈 🐩 🐱 🐩 🐶 🐩 🐶 \"]\n",
    "\n",
    "labels = ['cat', 'dog', 'cat', 'cat','dog'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "data = [['cat', \"🐈 🐯 🐱 🐩 🐱\"],\n",
    "        ['dog', \"🐶 🐶 🐈 🐶 🐩 🐈 🐶 🐶\"],\n",
    "        ['cat', \"🐈 🐈 🐯 🐶 🐈\"],\n",
    "        ['cat', \"🐈 🐈 🐈\"], \n",
    "        ['dog', \"🐶 🐶 🐯 🐈 🐩 🐱 🐩 🐶 🐩 🐶 \"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 🐈 🐯 🐱 🐩 🐱\n",
      "dog: 🐶 🐶 🐈 🐶 🐩 🐈 🐶 🐶\n",
      "cat: 🐈 🐈 🐯 🐶 🐈\n",
      "cat: 🐈 🐈 🐈\n",
      "dog: 🐶 🐶 🐯 🐈 🐩 🐱 🐩 🐶 🐩 🐶 \n"
     ]
    }
   ],
   "source": [
    "for label, item in data:\n",
    "    print(f\"{label}: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Calculate class priors</h2></center>\n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = set(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(corpus)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "doc_priors = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dog', 0.4)\n",
      "('cat', 0.6)\n"
     ]
    }
   ],
   "source": [
    "# For each label, find the probability of baseline occurance\n",
    "for label in labels:\n",
    "    doc_priors[label] = sum(1 for item_label, _ in data if item_label == label) / n_docs\n",
    "\n",
    "print(*doc_priors.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Conditional probabilities of word by class</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "vocab = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['🐈', '🐯', '🐱', '🐩', '🐱', '🐶', '🐶', '🐈', '🐶', '🐩', '🐈', '🐶', '🐶', '🐈', '🐈', '🐯', '🐶', '🐈', '🐈', '🐈', '🐈', '🐶', '🐶', '🐯', '🐈', '🐩', '🐱', '🐩', '🐶', '🐩', '🐶']\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "for _, doc in data:\n",
    "    vocab.extend(doc.split())\n",
    "    \n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'🐈', '🐩', '🐯', '🐱', '🐶'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of unique tokens, aka cardinality\n",
    "v = len(set(vocab))\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# A default dict of default dicts; inner default dict is probability\n",
    "cond_prob = defaultdict(lambda: defaultdict(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for label in labels:    \n",
    "    label_tokens = []\n",
    "    for item_label, doc in data:\n",
    "        # For a given label, get a list of all the tokens for all the docs \n",
    "        if item_label == label:\n",
    "            label_tokens.extend(doc.split())\n",
    "\n",
    "    for token in vocab:\n",
    "        # Find conditional probability: token count / total count\n",
    "        cond_prob[label][token] = label_tokens.count(token) / len(label_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog :\n",
      "🐈 0.16666666666666666\n",
      "🐯 0.05555555555555555\n",
      "🐱 0.05555555555555555\n",
      "🐩 0.2222222222222222\n",
      "🐶 0.5\n",
      "Cat :\n",
      "🐈 0.5384615384615384\n",
      "🐯 0.15384615384615385\n",
      "🐱 0.15384615384615385\n",
      "🐩 0.07692307692307693\n",
      "🐶 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "for label, sub_dict in cond_prob.items():\n",
    "    print(label.title(), \":\")\n",
    "    for token, prob in sub_dict.items():\n",
    "        print(token, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Test that each label is a probability mass function (pmf). A pmf sums to 1\n",
    "from math import isclose\n",
    "\n",
    "for label in labels:\n",
    "    assert isclose(sum(cond_prob[label].values()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Predicting with Naive Bayes</h2></center>\n",
    "\n",
    "1. Acquire and process the new data\n",
    "1. For each new data point, calculate the proportional probabilities for each class\n",
    "1. Pick the winning class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Given a new document, <br> calculate the proportional probabilities for each class</h2></center>\n",
    "\n",
    "$$ P(c | X) = P(c) •  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Define product function\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dog', 0.0010973936899862826)\n",
      "('cat', 0.0005461993627674101)\n"
     ]
    }
   ],
   "source": [
    "new_input = \"🐱\"\n",
    "# new_input = \"🐱 🐩 \"\n",
    "# new_input = \"🐱 🐩 🐩\"\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    # For each label, calculate the conditional probability based on the prior and the tokens that appear\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in new_input.split())\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pick the winning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog\n"
     ]
    }
   ],
   "source": [
    "label, prob = max(prob_predicted.items(), key=itemgetter(1))\n",
    "print(\"The predicted class is: \", end=\"\")\n",
    "print(*(k for k, v in prob_predicted.items() if v == prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "\n",
    "label, prob = max(prob_predicted.items(), key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(\"The predicted class is: \", end=\"\")\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/questions.png\" width=\"65%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<center><h2>Bonus Material</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Other implementations by Brian Spiering\n",
    "    - [Using NormalDist from statistics module](https://github.com/brianspiering/naive_bayes_classifer_in_python_3_8)\n",
    "    - [Naive Bayes for Text Classification](https://github.com/brianspiering/bayesian-text)\n",
    "    \n",
    "- [Implementation by mircealex](https://github.com/mircealex)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
