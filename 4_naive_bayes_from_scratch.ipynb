{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Implement-Naive-Bayes-From-Scratch\" data-toc-modified-id=\"Implement-Naive-Bayes-From-Scratch-0.1\">Implement Naive Bayes From Scratch</a></span></li><li><span><a href=\"#Actual-Bayes'-Theorem\" data-toc-modified-id=\"Actual-Bayes'-Theorem-0.2\">Actual Bayes' Theorem</a></span></li><li><span><a href=\"#By-The-End-Of-This-Session-You-Should-Be-Able-To:\" data-toc-modified-id=\"By-The-End-Of-This-Session-You-Should-Be-Able-To:-0.3\">By The End Of This Session You Should Be Able To:</a></span></li><li><span><a href=\"#Naive-Bayes-Classification-Steps\" data-toc-modified-id=\"Naive-Bayes-Classification-Steps-0.4\">Naive Bayes Classification Steps</a></span></li><li><span><a href=\"#Acquire-data-&amp;-preprocess\" data-toc-modified-id=\"Acquire-data-&amp;-preprocess-0.5\">Acquire data &amp; preprocess</a></span></li><li><span><a href=\"#Calculate-document-class-priors\" data-toc-modified-id=\"Calculate-document-class-priors-0.6\">Calculate document class priors</a></span></li><li><span><a href=\"#Calculate-conditional-probabilities-of-each-word-for-each-class\" data-toc-modified-id=\"Calculate-conditional-probabilities-of-each-word-for-each-class-0.7\">Calculate conditional probabilities of each word for each class</a></span></li><li><span><a href=\"#Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class\" data-toc-modified-id=\"Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class-0.8\">Given a new document without a label,  calculate the proportional probabilities for each class</a></span></li></ul></li><li><span><a href=\"#Pick-the-winning-class\" data-toc-modified-id=\"Pick-the-winning-class-1\">Pick the winning class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-1.1\">Takeaways</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Implement Naive Bayes From Scratch</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Bayes' Theorem\n",
    "------\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Naive Bayes Classification Steps\n",
    "-------\n",
    "\n",
    "1. Acquire labeled data\n",
    "1. Preprocess data\n",
    "1. Apply Mulitnomial Naive Bayes\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class\n",
    "1. Evaluate with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus  = [\"ğŸˆ ğŸ¯ ğŸ± ğŸ© ğŸ±\", \n",
    "           \"ğŸ¶ ğŸ¶ ğŸˆ ğŸ¶ ğŸ© ğŸˆ ğŸ¶ ğŸ¶\", \n",
    "           \"ğŸˆ ğŸˆ ğŸ¯ ğŸ¶ ğŸˆ\",  \n",
    "           \"ğŸˆ ğŸˆ ğŸˆ\",\n",
    "           \"ğŸ¶ ğŸ¶ ğŸ¯ ğŸˆ ğŸ© ğŸ± ğŸ© ğŸ¶ ğŸ© ğŸ¶ \"]\n",
    "\n",
    "labels = ['cat', 'dog', 'cat', 'cat','dog'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(labels, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ğŸˆ ğŸ¯ ğŸ± ğŸ© ğŸ±\n",
      "dog: ğŸ¶ ğŸ¶ ğŸˆ ğŸ¶ ğŸ© ğŸˆ ğŸ¶ ğŸ¶\n",
      "cat: ğŸˆ ğŸˆ ğŸ¯ ğŸ¶ ğŸˆ\n",
      "cat: ğŸˆ ğŸˆ ğŸˆ\n",
      "dog: ğŸ¶ ğŸ¶ ğŸ¯ ğŸˆ ğŸ© ğŸ± ğŸ© ğŸ¶ ğŸ© ğŸ¶ \n"
     ]
    }
   ],
   "source": [
    "for label, item in data:\n",
    "    print(f\"{label}: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(corpus)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.6)\n",
      "('dog', 0.4)\n"
     ]
    }
   ],
   "source": [
    "# For each label, find the probability of baseline occurance\n",
    "doc_priors = defaultdict(float)\n",
    "\n",
    "for label in labels:\n",
    "    doc_priors[label] = sum(1 for d in train if d.label == label) / n_docs\n",
    "\n",
    "print(*doc_priors.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['ğŸˆ', 'ğŸ¯', 'ğŸ±', 'ğŸ©', 'ğŸ±', 'ğŸ¶', 'ğŸ¶', 'ğŸˆ', 'ğŸ¶', 'ğŸ©', 'ğŸˆ', 'ğŸ¶', 'ğŸ¶', 'ğŸˆ', 'ğŸˆ', 'ğŸ¯', 'ğŸ¶', 'ğŸˆ', 'ğŸˆ', 'ğŸˆ', 'ğŸˆ', 'ğŸ¶', 'ğŸ¶', 'ğŸ¯', 'ğŸˆ', 'ğŸ©', 'ğŸ±', 'ğŸ©', 'ğŸ¶', 'ğŸ©', 'ğŸ¶']\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = []\n",
    "\n",
    "for doc in train:\n",
    "    vocab.extend(doc.tokens)\n",
    "    \n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ğŸˆ', 'ğŸ©', 'ğŸ¯', 'ğŸ±', 'ğŸ¶'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of unique tokens, aka cardinality\n",
    "v = len(set(vocab))\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'cat': defaultdict(float,\n",
       "                         {'ğŸˆ': 0.5384615384615384,\n",
       "                          'ğŸ¯': 0.15384615384615385,\n",
       "                          'ğŸ±': 0.15384615384615385,\n",
       "                          'ğŸ©': 0.07692307692307693,\n",
       "                          'ğŸ¶': 0.07692307692307693}),\n",
       "             'dog': defaultdict(float,\n",
       "                         {'ğŸˆ': 0.16666666666666666,\n",
       "                          'ğŸ¯': 0.05555555555555555,\n",
       "                          'ğŸ±': 0.05555555555555555,\n",
       "                          'ğŸ©': 0.2222222222222222,\n",
       "                          'ğŸ¶': 0.5})})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A default dict of default dicts; inner default dict is probability\n",
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    label_tokens = []\n",
    "    for doc in train:\n",
    "         # For a given label, get a list of all the tokens for all the docs \n",
    "        if doc.label == label:\n",
    "            label_tokens.extend(doc.tokens)\n",
    "\n",
    "    for token in vocab:\n",
    "        # Find conditional probability: token count / total count\n",
    "        cond_prob[label][token] = label_tokens.count(token) / len(label_tokens) \n",
    "\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a probability mass function (pmf). A pmf sums to 1\n",
    "from math import isclose\n",
    "\n",
    "for label in labels:\n",
    "    assert isclose(sum(cond_prob[label].values()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) â€¢  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.09230769230769231)\n",
      "('dog', 0.022222222222222223)\n"
     ]
    }
   ],
   "source": [
    "test = LabeledTextData(id_num=90, label=None, tokens=\"ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=91, label=None, tokens=\"ğŸ¶ ğŸ¶\".split()) \n",
    "# test = LabeledTextData(id_num=92, label=None, tokens=\"ğŸ¶ ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=93, label=None, tokens=\"ğŸˆ ğŸˆ ğŸ¶ ğŸ¶ ğŸ© ğŸ± ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=94, label=None, tokens=\"ğŸ¬ \".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    # For each label, calculate the conditional probability based on the prior and the tokens that appear\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.tokens)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the winning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(\"The predicted class is: \", end=\"\")\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Naive Bayes (NB) is a simple and powerful algorithm for text classification\n",
    "- To apply NB, follow a step-by-step process to calculate each probability\n",
    "- Python's Standard Library has functions to write elegant and performant code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
